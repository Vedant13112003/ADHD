{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nitrc.org/plugins/mwiki/index.php/neurobureau:AthenaPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from Code.data_generator import FMRIDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv3D, MaxPool3D, TimeDistributed, Flatten, LSTM, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Dataframes\u001b[39;00m\n\u001b[32m      6\u001b[39m dataset_dir = \u001b[33m\"\u001b[39m\u001b[33m/pylon5/cc5614p/deopha32/fmri_images/model_data/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model_train_data = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m\"\u001b[39m\u001b[33m/Users/vedantshirapure/Downloads/Diagnosing-ADHD-With-ConvLSTM/Data/training_data_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(file_num) )\n\u001b[32m      9\u001b[39m model_val_data = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m/Users/vedantshirapure/Downloads/Diagnosing-ADHD-With-ConvLSTM/Data/validatation_data_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(file_num) )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Dictionary of data values\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================ DATA WORK ============================\n",
    "\n",
    "file_num = '1'\n",
    "\n",
    "# Dataframes\n",
    "dataset_dir = \"/pylon5/cc5614p/deopha32/fmri_images/model_data/\"\n",
    "model_train_data = pd.read_csv(\"/Users/vedantshirapure/Downloads/Diagnosing-ADHD-With-ConvLSTM/Data/training_data_{}\".format(file_num) )\n",
    "\n",
    "model_val_data = pd.read_csv(\"/Users/vedantshirapure/Downloads/Diagnosing-ADHD-With-ConvLSTM/Data/validatation_data_{}\".format(file_num) )\n",
    "\n",
    "# Dictionary of data values\n",
    "partition = {'train': model_train_data['Image'].values, \n",
    "             'validation': model_val_data['Image'].values}\n",
    "\n",
    "# Training Data\n",
    "train_labels = {}\n",
    "for index, row in model_train_data.iterrows():\n",
    "    train_labels[row['Image']] = row['DX']\n",
    "    \n",
    "# Validation Data\n",
    "val_labels = {}\n",
    "for index, row in model_val_data.iterrows():\n",
    "    val_labels[row['Image']] = row['DX']\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import CSVLogger  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ MODEL META ============================\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 6\n",
    "input_shape=(177,28,28,28,1)\n",
    "\n",
    "train_steps_per_epoch = model_train_data.shape[0] // batch_size\n",
    "validate_steps_per_epoch = model_val_data.shape[0] // batch_size\n",
    "\n",
    "# Generators\n",
    "training_generator = FMRIDataGenerator(partition['train'], train_labels, dataset_dir, batch_size)\n",
    "validation_generator = FMRIDataGenerator(partition['validation'], val_labels, dataset_dir, batch_size)\n",
    "\n",
    "curr_time = f'{datetime.now():%H-%M-%S%z_%m%d%Y}'\n",
    "logger_path = \"/pylon5/cc5614p/deopha32/Saved_Models/adhd-fmri-history_cv{num}_{time}.csv\".format(num=file_num,time=curr_time)\n",
    "\n",
    "csv_logger = CSVLogger(logger_path, append=True)\n",
    "\n",
    "callbacks = [csv_logger]\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # Import Sequential model\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv3D, MaxPool3D, Flatten, LSTM, Dense  # Import necessary layers\n",
    "from tensorflow.keras import optimizers  # Import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ MODEL ARCHITECTURE ============================\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    cnn_lstm_model = Sequential()\n",
    "\n",
    "    # Conv3D layer with TimeDistributed wrapper\n",
    "    cnn_lstm_model.add(TimeDistributed(Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu'),\n",
    "                                       input_shape=input_shape, name=\"Input_Conv_Layer\"))\n",
    "\n",
    "    # MaxPool3D layer with TimeDistributed wrapper\n",
    "    cnn_lstm_model.add(TimeDistributed(MaxPool3D(pool_size=(2, 2, 2),\n",
    "                                                  strides=(2, 2, 2),\n",
    "                                                  padding='valid'),\n",
    "                                       name=\"Pool_Layer_1\"))\n",
    "\n",
    "    # Flatten layer with TimeDistributed wrapper\n",
    "    cnn_lstm_model.add(TimeDistributed(Flatten(), name=\"Flatten_Layer\"))\n",
    "    \n",
    "# LSTM layer on CPU\n",
    "with tf.device('/cpu:0'):\n",
    "    cnn_lstm_model.add(LSTM(10, dropout=0.3, recurrent_dropout=0.3, name=\"LSTM_Layer\"))\n",
    "\n",
    "# Output layer with Dense layer on GPU\n",
    "with tf.device('/gpu:0'):\n",
    "    cnn_lstm_model.add(Dense(1, activation='sigmoid', name=\"Output_Dense_Layer\"))\n",
    "\n",
    "# Compile the model\n",
    "cnn_lstm_model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/a/46216013/9221241\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "         number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "         number_size = 8.0\n",
    "\n",
    "    total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/46216013/9221241\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "         number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "         number_size = 8.0\n",
    "\n",
    "    total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeDistributed' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_model_memory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn_lstm_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mget_model_memory_usage\u001b[0;34m(batch_size, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     internal_model_mem_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m get_model_memory_usage(batch_size, l)\n\u001b[1;32m     12\u001b[0m single_layer_mem \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_shape\u001b[49m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TimeDistributed' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "#get_model_memory_usage(32, cnn_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Conv_Layer                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140608</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ LSTM_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,624,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Dense_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Conv_Layer                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m177\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m,    │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool_Layer_1 (\u001b[38;5;33mTimeDistributed\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m177\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m177\u001b[0m, \u001b[38;5;34m140608\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ LSTM_Layer (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │     \u001b[38;5;34m5,624,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Dense_Layer (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,626,563</span> (21.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,626,563\u001b[0m (21.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,626,563</span> (21.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,626,563\u001b[0m (21.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/pylon5/cc5614p/deopha32/fmri_images/model_data/Peking_1_sfnwmrda2443191_session_1_rest_1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([val_labels[img_id] \u001b[38;5;28;01mfor\u001b[39;00m img_id \u001b[38;5;129;01min\u001b[39;00m partition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m--> 106\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_lstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_pred_probs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/University/Capestone Project /Diagnosing-ADHD-With-ConvLSTM/Notebooks/../Code/data_generator.py:39\u001b[0m, in \u001b[0;36mFMRIDataGenerator.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     36\u001b[0m list_IDs_temp \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_IDs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m indexes]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Generate data\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_IDs_temp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/Desktop/University/Capestone Project /Diagnosing-ADHD-With-ConvLSTM/Notebooks/../Code/data_generator.py:56\u001b[0m, in \u001b[0;36mFMRIDataGenerator.__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m     53\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_IDs_temp):\n\u001b[0;32m---> 56\u001b[0m     X[i,] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     y[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[img_path]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X,y\n",
      "File \u001b[0;32m~/Desktop/University/Capestone Project /Diagnosing-ADHD-With-ConvLSTM/Notebooks/../Code/data_generator.py:63\u001b[0m, in \u001b[0;36mFMRIDataGenerator.preprocess_image\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_path):\n\u001b[0;32m---> 63\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     pp_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_length:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nibabel/loadsave.py:103\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/pylon5/cc5614p/deopha32/fmri_images/model_data/Peking_1_sfnwmrda2443191_session_1_rest_1.nii.gz'"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "#                              f1_score, roc_auc_score, confusion_matrix, \n",
    "#                              ConfusionMatrixDisplay, roc_curve, auc)\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ============================ MODEL TRAINING ============================\n",
    "# # Make sure to capture the training history\n",
    "# history = cnn_lstm_model.fit(\n",
    "#     training_generator,\n",
    "#     steps_per_epoch=train_steps_per_epoch,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validate_steps_per_epoch,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # ============================ EVALUATION METRICS ============================\n",
    "# # Generate predictions\n",
    "# print(\"Generating predictions...\")\n",
    "# y_true = np.array([val_labels[img_id] for img_id in partition['validation']])\n",
    "# y_pred_probs = cnn_lstm_model.predict(validation_generator, verbose=1)\n",
    "# y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# # Calculate metrics\n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "# precision = precision_score(y_true, y_pred)\n",
    "# recall = recall_score(y_true, y_pred)\n",
    "# f1 = f1_score(y_true, y_pred)\n",
    "# roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
    "\n",
    "# print(f\"\\nValidation Metrics:\")\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# # ============================ VISUALIZATIONS ============================\n",
    "# # Plot training history\n",
    "# plt.figure(figsize=(15, 6))\n",
    "\n",
    "# # Loss plot\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend()\n",
    "\n",
    "# # Accuracy plot\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('/pylon5/cc5614p/deopha32/Saved_Models/training_history.png')\n",
    "# plt.close()\n",
    "\n",
    "# # Confusion Matrix\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "#                               display_labels=['Control', 'ADHD'])\n",
    "# disp.plot(cmap=plt.cm.Blues)\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.savefig('/pylon5/cc5614p/deopha32/Saved_Models/confusion_matrix.png')\n",
    "# plt.close()\n",
    "\n",
    "# # ROC Curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "#          label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.savefig('/pylon5/cc5614p/deopha32/Saved_Models/roc_curve.png')\n",
    "# plt.close()\n",
    "\n",
    "# # Save metrics to file\n",
    "# with open('/pylon5/cc5614p/deopha32/Saved_Models/evaluation_metrics.txt', 'w') as f:\n",
    "#     f.write(f'Accuracy: {accuracy:.4f}\\n')\n",
    "#     f.write(f'Precision: {precision:.4f}\\n')\n",
    "#     f.write(f'Recall: {recall:.4f}\\n')\n",
    "#     f.write(f'F1 Score: {f1:.4f}\\n')\n",
    "#     f.write(f'ROC AUC: {roc_auc:.4f}\\n')\n",
    "\n",
    "# print(\"All evaluation metrics and plots saved successfully!\")\n",
    "\n",
    "# ============================ EVALUATION METRICS ============================\n",
    "# Generate predictions\n",
    "print(\"Generating predictions...\")\n",
    "y_true = np.array([val_labels[img_id] for img_id in partition['validation']])\n",
    "y_pred_probs = cnn_lstm_model.predict(validation_generator, verbose=1)\n",
    "y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
